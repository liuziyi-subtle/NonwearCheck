{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint, sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost\n",
    "import treelite\n",
    "\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = pd.read_csv(\"/data/data/NonwearCheck/450/Results/df_feat_ppg_g.csv\", index_col=None)\n",
    "df_feats = df_feats.iloc[shuffle(range(len(df_feats)), random_state=0), :]\n",
    "\n",
    "df_objects = pd.read_csv(\"/data/data/NonwearCheck/450/Results/df_object_ppg_g.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_cols = [c for c in df_feats.columns if \"ppg\" in c]\n",
    "target_col  = \"wear_category_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  0.9973353762115711\n"
     ]
    }
   ],
   "source": [
    "X_cols = feats_cols\n",
    "y_col  = target_col\n",
    "\n",
    "X_train, y_train = df_feats.loc[:, X_cols].values, df_feats.loc[:, y_col].values\n",
    "X_test,  y_test  = df_feats.loc[:, X_cols].values, df_feats.loc[:, y_col].values\n",
    "\n",
    "shuffle_index = shuffle(range(len(X_train)), random_state=0)\n",
    "X_train = X_train[shuffle_index, :]\n",
    "y_train = y_train[shuffle_index]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "D_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "D_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {'max_depth': 5, 'objective':'binary:logistic'}\n",
    "num_iter = 15\n",
    "bst_all = xgboost.train(params, D_train, num_iter, [(D_train, 'train')], verbose_eval=False)\n",
    "\n",
    "probs = bst_all.predict(D_test)\n",
    "preds = np.array(probs) > 0.7\n",
    "\n",
    "print(\"MAE: \", accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_all.feature_names = X_cols\n",
    "key_value = bst_all.get_score(importance_type=\"gain\")\n",
    "key_value = sorted(key_value.items(), key = lambda kv:(kv[1], kv[0]))[::-1][:50]\n",
    "top_feats = [kv[0] for kv in key_value]\n",
    "# top_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32772480813553015\n",
      "32772480813553082\n",
      "32772480813553019\n",
      "32772480813553015\n",
      "32772480813553082\n",
      "32772480813553019\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 6 into shape (203)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8c43df832029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mcorrcoefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0msegment_accs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_accs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0maccs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mappend_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mappend_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 6 into shape (203)"
     ]
    }
   ],
   "source": [
    "X_cols_candidates = top_feats\n",
    "y_col = target_col\n",
    "\n",
    "params = {'max_depth': 5, 'objective':'binary:logistic'}\n",
    "num_iter = 15\n",
    "\n",
    "segment_ids = df_feats['segment_id'].unique()\n",
    "\n",
    "accs = []\n",
    "segment_accs = []\n",
    "append_feats = []\n",
    "feats_tobe_combined = []\n",
    "corrcoefs = []\n",
    "\n",
    "df_results = pd.DataFrame({})\n",
    "\n",
    "for f in X_cols_candidates:\n",
    "    combined_feats = []\n",
    "    if f not in combined_feats:\n",
    "        combined_feats.append(f)\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    y_probs_list, y_preds_list, y_test_list = [], [], []\n",
    "    \n",
    "    for segment_id in segment_ids:\n",
    "        test_index = df_feats['segment_id'] == segment_id\n",
    "        X_train, y_train = df_feats.loc[~test_index, combined_feats].values, df_feats.loc[~test_index, y_col].values\n",
    "        X_test,  y_test  = df_feats.loc[test_index, combined_feats].values, df_feats.loc[test_index, y_col].values\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.transform(X_test)\n",
    "        \n",
    "        D_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        D_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        bst = xgboost.train(params, D_train, num_iter, [(D_train, 'train')], verbose_eval=False)\n",
    "        probs = bst.predict(D_test)\n",
    "        preds = np.array(probs) > 0.7\n",
    "        acc = accuracy_score(preds, list(y_test))\n",
    "        \n",
    "        segment_accs.append(acc)\n",
    "        \n",
    "        y_probs_list.extend(probs)\n",
    "        y_preds_list.extend(preds)\n",
    "        y_test_list.extend(list(y_test))\n",
    "        print(segment_id)\n",
    "    \n",
    "    acc = accuracy_score(y_test_list, y_preds_list)\n",
    "    accs.append(acc)\n",
    "    \n",
    "    append_feats.append(f)\n",
    "    \n",
    "    if not feats_tobe_combined:\n",
    "        for ftc in feats_tobe_combined:\n",
    "            corrcoef = np.corrcoef(df_feats[f], df_feats[ftc])[0][1]\n",
    "            corrcoefs.append(corrcoef)\n",
    "        \n",
    "segment_accs = np.array(segment_accs).reshape(-1, len(segment_ids))\n",
    "accs = np.array(accs).reshape(-1, 1)\n",
    "append_feats = np.array(append_feats).reshape(-1, 1)\n",
    "\n",
    "if not feats_tobe_combined:\n",
    "    corrcoefs = np.array(corrcoefs).reshape(-1, len(feats_tobe_combined))\n",
    "    df_results = np.concatenate([append_feats, corrcoefs, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + feats_tobe_combined + [\"accs\"] + list(segment_ids)\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "else:\n",
    "    df_results = np.concatenate([append_feats, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + [\"accs\"] + list(segment_ids)\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "\n",
    "df_results.to_csv(\"df_results_1feat.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-529f105f102f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfeats_tobe_combined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcorrcoefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrcoefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats_tobe_combined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mdf_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mappend_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_accs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"append_feats\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfeats_tobe_combined\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"accs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (0)"
     ]
    }
   ],
   "source": [
    "segment_accs = np.array(segment_accs).reshape(-1, 3)\n",
    "accs = np.array(accs).reshape(-1, 1)\n",
    "append_feats = np.array(append_feats).reshape(-1, 1)\n",
    "\n",
    "if not feats_tobe_combined:\n",
    "    corrcoefs = np.array(corrcoefs).reshape(-1, len(feats_tobe_combined))\n",
    "    df_results = np.concatenate([append_feats, corrcoefs, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + feats_tobe_combined + [\"accs\"] + list(segment_ids)\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "else:\n",
    "    df_results = np.concatenate([append_feats, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + [\"accs\"] + list(segment_ids)\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "\n",
    "df_results.to_csv(\"df_results_1feat.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if feats_tobe_combined:\n",
    "    corrcoefs = np.array(corrcoefs).reshape(-1, len(feats_tobe_combined))\n",
    "    df_results = np.concatenate([append_feats, corrcoefs, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + feats_tobe_combined + [\"accs\"] + list(segment_ids[:3])\n",
    "    print(len(columns))\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "else:\n",
    "    df_results = np.concatenate([append_feats, accs, segment_accs], axis=1)\n",
    "    columns = [\"append_feats\"] + [\"accs\"] + list(segment_ids[:3])\n",
    "    df_results = pd.DataFrame(df_results, columns=columns)\n",
    "\n",
    "df_results.to_csv(\"df_results_1feat.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>append_feats</th>\n",
       "      <th>accs</th>\n",
       "      <th>32772480813553015</th>\n",
       "      <th>32772480813553082</th>\n",
       "      <th>32772480813553019</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ppg_g__ratio_value_number_to_time_series_length</td>\n",
       "      <td>0.997872340425532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.993103448275862</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ppg_g__change_quantiles__f_agg_\"mean\"__isabs_T...</td>\n",
       "      <td>0.9957446808510638</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9862068965517241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        append_feats                accs  \\\n",
       "0    ppg_g__ratio_value_number_to_time_series_length   0.997872340425532   \n",
       "1  ppg_g__change_quantiles__f_agg_\"mean\"__isabs_T...  0.9957446808510638   \n",
       "\n",
       "  32772480813553015   32772480813553082 32772480813553019  \n",
       "0               1.0   0.993103448275862               1.0  \n",
       "1               1.0  0.9862068965517241               1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1595313013 0.994572591587517\n",
      "1588257455 1.0\n",
      "1588257312 0.9459459459459459\n",
      "1595383255 1.0\n",
      "1595388059 1.0\n",
      "1586841055 1.0\n",
      "1588257368 1.0\n",
      "1586843082 1.0\n",
      "1595313028 0.9433465085638999\n",
      "1595387992 1.0\n",
      "1588257385 1.0\n",
      "1586843123 1.0\n",
      "1595313107 1.0\n",
      "1595383319 1.0\n",
      "1586841282 1.0\n",
      "1595303876 0.0\n",
      "1595303902 1.0\n",
      "1595388039 1.0\n",
      "1595313000 1.0\n",
      "1595303970 1.0\n",
      "1586843703 1.0\n",
      "1588257400 1.0\n",
      "1595388133 1.0\n",
      "1586843360 0.0\n",
      "1586841154 0.883495145631068\n",
      "1586843044 1.0\n",
      "1586842986 1.0\n",
      "1588257418 1.0\n",
      "1588257437 1.0\n",
      "1595313066 1.0\n",
      "1586843333 1.0\n",
      "1586841443 1.0\n",
      "1586843057 1.0\n",
      "1595383285 1.0\n",
      "1588257346 1.0\n",
      "1595313094 1.0\n",
      "1595303946 0.9914529914529915\n",
      "1595383302 1.0\n",
      "1595388118 1.0\n",
      "1586842998 1.0\n",
      "1595303958 1.0\n",
      "1586843686 1.0\n",
      "1588257483 1.0\n",
      "1586843727 1.0\n",
      "1586843580 0.0\n",
      "1586843071 1.0\n",
      "1586843345 1.0\n",
      "1586841392 1.0\n",
      "1586843478 1.0\n",
      "1586843563 0.0\n",
      "1586843527 0.0\n",
      "1586843501 1.0\n",
      "1586843548 0.0\n",
      "1586843675 1.0\n",
      "=================================================\n",
      "ppg__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"mean\"  --  0.9657731501993797  --  0.296755808620785\n"
     ]
    }
   ],
   "source": [
    "# 逐个查看特征的分类性能\n",
    "params = {'max_depth': 5, 'objective':'binary:logistic'}\n",
    "num_iter = 15\n",
    "X_cols_candidates = ['ppg__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"mean\"']\n",
    "\n",
    "for f in X_cols_candidates:\n",
    "    combined_feats = [\n",
    "        'ppg__autocorrelation__lag_1'\n",
    "                      ]\n",
    "    if f not in combined_feats:\n",
    "        combined_feats.append(f)\n",
    "    else:\n",
    "        continue\n",
    "    segment_ids = df_features['segment_id'].unique()\n",
    "    y_probs_list, y_preds_list, y_test_list, segment_score = [], [], [], {}\n",
    "    for segment_id in segment_ids:\n",
    "        test_index = df_features['segment_id'] == segment_id\n",
    "        X_train, y_train = df_features.loc[~test_index, combined_feats].values, df_features.loc[~test_index, 'wear_category_id'].values\n",
    "        X_test,  y_test  = df_features.loc[test_index, combined_feats].values, df_features.loc[test_index, 'wear_category_id'].values\n",
    "        \n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test  = scaler.transform(X_test)\n",
    "        \n",
    "        D_train = xgboost.DMatrix(X_train, label=y_train)\n",
    "        D_test = xgboost.DMatrix(X_test, label=y_test)\n",
    "        \n",
    "        bst = xgboost.train(params, D_train, num_iter, [(D_train, 'train')], verbose_eval=False)\n",
    "        probs = bst.predict(D_test)\n",
    "        preds = np.array(probs) > 0.7\n",
    "        \n",
    "        y_probs_list.extend(probs)\n",
    "        y_preds_list.extend(preds)\n",
    "        y_test_list.extend(list(y_test))\n",
    "        print(segment_id, accuracy_score(preds, list(y_test)))\n",
    "    print(\"=================================================\")\n",
    "#     print(f, ' -- ', accuracy_score(y_test_list, y_preds_list))\n",
    "    print(f, ' -- ', accuracy_score(y_test_list, y_preds_list), ' -- ', np.corrcoef(df_features[f], df_features['ppg__autocorrelation__lag_1'])[0][1])  # , ' -- ', np.corrcoef(df_features[f], df_features['Resultant__ar_0'])[0][1])\n",
    "#     print(f, ' -- ', accuracy_score(y_test_list, y_preds_list), ' -- ', np.corrcoef(df_features[f], df_features['ppg__agg_linear_trend__attr_\"intercept\"__chunk_len_10__f_agg_\"mean\"'])[0][1])\n",
    "#     print(f, ' -- ', accuracy_score(y_test_list, y_preds_list), ' -- ', np.corrcoef(df_features[f], df_features['ppg__cid_ce__normalize_True'])[0][1])# , ' -- ', np.corrcoef(df_features[f], df_features['Resultant__ar_0'])[0][1])\n",
    "#     print(f, ' -- ', accuracy_score(y_test_list, y_preds_list), ' -- ', np.corrcoef(df_features[f], df_features['ppg__change_quantiles__f_agg_\"mean\"__isabs_True__qh_0.6__ql_0.2'])[0][1])\n",
    "#     print(f, ' -- ', accuracy_score(y_test_list, y_preds_list), ' -- ', np.corrcoef(df_features[f], df_features['ppg__fft_aggregated__aggtype_\"centroid\"'])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
