{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from random import randint, sample\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import xgboost\n",
    "import treelite\n",
    "\n",
    "\n",
    "sns.set(style=\"ticks\")\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pd.set_option('display.max_rows', 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/data/NonwearCheck/450/Results/annotations.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-cb16c0f7b9bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/data/data/NonwearCheck/450/Results/annotations.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrecord_annotation_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrecord_annotation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'record_annotations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/data/NonwearCheck/450/Results/annotations.json'"
     ]
    }
   ],
   "source": [
    "with open('/data/data/NonwearCheck/450/Results/annotations.json', 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "record_annotation_index = {}\n",
    "for record_annotation in annotations['record_annotations']:\n",
    "    if record_annotation['id'] not in record_annotation_index:\n",
    "        record_annotation_index[record_annotation['id']] = {}\n",
    "    id = record_annotation['id']\n",
    "    record_annotation.pop('id')\n",
    "    record_annotation_index[id].update(record_annotation)\n",
    "\n",
    "segment_annotation_index = {}\n",
    "for segment_annotation in annotations['segment_annotations']:\n",
    "    if segment_annotation['id'] not in segment_annotation_index:\n",
    "        segment_annotation_index[segment_annotation['id']] = {}\n",
    "    id = segment_annotation['id']\n",
    "    segment_annotation.pop('id')\n",
    "    segment_annotation_index[id].update(segment_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feats = pd.read_csv(\"/data/Results/df_feat_ppg_ir.csv\", index_col=None)\n",
    "df_feats = df_feats.iloc[shuffle(range(len(df_feats)), random_state=0), :]\n",
    "\n",
    "df_objects = pd.read_csv(\"/data/Results/df_object_ppg_ir.csv\", index_col=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_cols = [c for c in df_feats.columns if \"ppg\" in c]\n",
    "target_col = \"wear_category_id\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 全数据构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:18:54] WARNING: /xgboost/src/learner.cc:1043: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9800347609073489"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 利用xgboost选择前50个特征分析\n",
    "params = {'max_depth': 6, 'objective': 'binary:logistic', \"n_jobs\": -1}\n",
    "num_iter = 20\n",
    "\n",
    "X_cols, y_col = [\n",
    "    'ppg-ir__number_peaks__n_3',\n",
    "    'ppg-ir__number_peaks__n_10',\n",
    "    'ppg-ir__autocorrelation__lag_2',\n",
    "    'ppg-ir__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"max\"',\n",
    "    'ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"',\n",
    "    'ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"',\n",
    "    'ppg-ir__binned_entropy__max_bins_10',\n",
    "    'ppg-ir__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8',\n",
    "    'ppg-ir__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8'\n",
    "                       ], target_col\n",
    "\n",
    "X, y = df_feats.loc[:, X_cols].values, df_feats.loc[:, y_col].values\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "\n",
    "D_train = xgboost.DMatrix(X, label=y)\n",
    "D_test = xgboost.DMatrix(X, label=y)\n",
    "\n",
    "bst = xgboost.train(params, D_train, num_iter, [(D_train, 'train')], verbose_eval=False)\n",
    "\n",
    "accuracy_score(y, bst.predict(D_test) > 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:19:03] /workspace/src/compiler/ast_native.cc:44: Using ASTNativeCompiler\n",
      "[11:19:03] /workspace/src/compiler/ast/split.cc:24: Parallel compilation disabled; all member trees will be dumped to a single source file. This may increase compilation time and memory usage.\n",
      "[11:19:03] /workspace/src/c_api/c_api.cc:286: Code generation finished. Writing code to files...\n",
      "[11:19:03] /workspace/src/c_api/c_api.cc:291: Writing file recipe.json...\n",
      "[11:19:03] /workspace/src/c_api/c_api.cc:291: Writing file header.h...\n",
      "[11:19:03] /workspace/src/c_api/c_api.cc:291: Writing file main.c...\n"
     ]
    }
   ],
   "source": [
    "model = treelite.Model.from_xgboost(bst)\n",
    "\n",
    "model.export_srcpkg(platform='unix', toolchain='gcc', pkgpath='./model_20210816_002.zip',\n",
    "                    libname='mymodel.so', verbose=True, params={'quantize': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 验证和C一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_object_ids = [5000]# list(range(3000, 3004))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 待验证数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13230203, 13230173, 13229802, 13230442, 13228897, 13231315,\n",
       "       13227935, 13230280, 13228136, 13231965, 13228368, 13229783,\n",
       "       13228231, 13229994, 13229018, 13229701, 13229501, 13230017,\n",
       "       13229313, 13229432, 13229118, 13230280, 13229857, 13229976,\n",
       "       13228734, 13229642, 13229548, 13229988, 13229345, 13229248,\n",
       "       13230175, 13228941, 13229246, 13229156, 13229100, 13229680,\n",
       "       13228774, 13229980, 13229188, 13230208, 13228493, 13229794,\n",
       "       13228541, 13229949, 13228552, 13229909, 13228546, 13229518,\n",
       "       13229137, 13229255, 13229191, 13228707, 13229130, 13229288,\n",
       "       13229336, 13228749, 13229527, 13229401, 13229928, 13229863,\n",
       "       13228635, 13229641, 13229312, 13230201, 13228903, 13229414,\n",
       "       13229466, 13229270, 13229348, 13228732, 13229308, 13229332,\n",
       "       13229293, 13229271, 13229068, 13228229, 13229915, 13229749,\n",
       "       13230379, 13228453, 13229118, 13228419, 13231276, 13228809,\n",
       "       13229652, 13228644, 13229635, 13229153, 13229878, 13228960,\n",
       "       13229344, 13227976, 13229668, 13228697, 13230353, 13228354,\n",
       "       13229973, 13227340, 13229348, 13228341, 13229847, 13228797,\n",
       "       13228646, 13229006, 13228776, 13229130, 13231244, 13230303,\n",
       "       13225894, 13229818, 13232313, 13230511, 13229458, 13227655,\n",
       "       13230241, 13231163, 13231565, 13228953, 13229131, 13230895,\n",
       "       13230088, 13230728, 13228642, 13230077, 13230315, 13229617,\n",
       "       13229360, 13229237])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_object_ids = [10999]\n",
    "mask = np.isin(df_objects['id'], selected_object_ids)\n",
    "mask = np.where(mask)[0]\n",
    "df_objects.loc[mask, 'ppg-ir'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ppg-ir__number_peaks__n_3</th>\n",
       "      <th>ppg-ir__number_peaks__n_10</th>\n",
       "      <th>ppg-ir__autocorrelation__lag_2</th>\n",
       "      <th>ppg-ir__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"max\"</th>\n",
       "      <th>ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"</th>\n",
       "      <th>ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"</th>\n",
       "      <th>ppg-ir__binned_entropy__max_bins_10</th>\n",
       "      <th>ppg-ir__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8</th>\n",
       "      <th>ppg-ir__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.08966</td>\n",
       "      <td>8231.677333</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.057512</td>\n",
       "      <td>1.642766</td>\n",
       "      <td>0.753176</td>\n",
       "      <td>0.260478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ppg-ir__number_peaks__n_3  ppg-ir__number_peaks__n_10  \\\n",
       "10999                       18.0                         6.0   \n",
       "\n",
       "       ppg-ir__autocorrelation__lag_2  \\\n",
       "10999                         0.08966   \n",
       "\n",
       "       ppg-ir__agg_linear_trend__attr_\"intercept\"__chunk_len_50__f_agg_\"max\"  \\\n",
       "10999                                        8231.677333                       \n",
       "\n",
       "       ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"mean\"  \\\n",
       "10999                                           0.026348                     \n",
       "\n",
       "       ppg-ir__agg_linear_trend__attr_\"stderr\"__chunk_len_10__f_agg_\"max\"  \\\n",
       "10999                                           0.057512                    \n",
       "\n",
       "       ppg-ir__binned_entropy__max_bins_10  \\\n",
       "10999                             1.642766   \n",
       "\n",
       "       ppg-ir__change_quantiles__f_agg_\"var\"__isabs_False__qh_1.0__ql_0.8  \\\n",
       "10999                                           0.753176                    \n",
       "\n",
       "       ppg-ir__change_quantiles__f_agg_\"var\"__isabs_True__qh_1.0__ql_0.8  \n",
       "10999                                           0.260478                  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats = df_feats.loc[selected_object_ids, X_cols]\n",
    "feats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9985404], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = xgboost.DMatrix(feats.values)\n",
    "bst.predict(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "\n",
    "_logger = logging.getLogger('nni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "_logger.info(\n",
    "            \"Creating graph json, writing to. Visualization enabled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
